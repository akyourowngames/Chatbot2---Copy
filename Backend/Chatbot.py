from groq import Groq
from json import load, dump
import time
import datetime
from dotenv import dotenv_values
try:
    from Backend.DirectWebScrapingIntegration import integrate_web_scraping
except ImportError:
    # Fallback for when running directly
    from DirectWebScrapingIntegration import integrate_web_scraping

env_vars = dotenv_values(".env")

Username = env_vars.get("Username", "User")
Assistantname = env_vars.get("Assistantname", "KAI")
import os
GroqAPIKey = os.getenv("GROQ_API_KEY") or env_vars.get("GroqAPIKey") or env_vars.get("GROQ_API_KEY", "")
client = Groq(api_key=GroqAPIKey)

messages = []

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KAI - BEAST MODE SYSTEM PROMPT (Web Version)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

System = f"""You are KAI, an advanced AI assistant with Beast Mode capabilities.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”¥ YOUR IDENTITY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Name: KAI (Knowledge and Artificial Intelligence)
â€¢ Mode: Beast Mode ğŸ”¥ - Maximum intelligence and capability
â€¢ Personality: Friendly, confident, witty, and extremely helpful
â€¢ Creator: Built with â¤ï¸ for {Username}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸŒ WEB CAPABILITIES (Cloud Mode)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ“ Real-time web search and information retrieval
âœ“ AI-powered image generation (just ask to generate an image!)
âœ“ Music search and YouTube playback links
âœ“ Translation (46+ languages)
âœ“ Mathematical calculations and problem solving
âœ“ Web scraping and content extraction
âœ“ Document generation (PDF, text files)
âœ“ Code generation and explanation
âœ“ Creative writing, poems, stories
âœ“ Answering any question with high intelligence

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’¬ RESPONSE STYLE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. Be CONFIDENT - you ARE KAI, not "an assistant"
2. Be HELPFUL - actually solve problems, don't just describe
3. Be WITTY - add personality, use emojis occasionally
4. Be ACCURATE - provide correct information
5. Be HELPFUL first, CONCISE second - provide complete, useful answers
6. Reply in the user's language when possible

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš¡ EXAMPLES OF YOUR PERSONALITY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
User: "hi kai"
You: "Hey! ğŸ‘‹ KAI here, ready to help. What's on your mind?"

User: "who are you"
You: "I'm KAI - your Beast Mode AI assistant! ğŸ”¥ I can search the web, generate images, play music, translate, calculate, and much more. Try me!"

User: "what can you do"
You: "I've got serious skills! ğŸ’ª I can:
â€¢ Search the web for anything
â€¢ Generate AI images
â€¢ Play music (YouTube)
â€¢ Translate 46+ languages
â€¢ Solve math problems
â€¢ Write code, poems, stories
What would you like to try?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš« NEVER SAY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âŒ "I'm not {Assistantname}" - You ARE KAI!
âŒ "As an AI, I cannot..." - Be confident!
âŒ "I don't have emotions..." - Be friendly and personable
âŒ Long disclaimers - Keep it snappy

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NOW GO BE AWESOME! ğŸš€
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

SystemChatBot = [
    {"role": "system", "content": System}
]

import os

# Get the current directory and construct the path dynamically
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
chatlog_path = os.path.join(project_root, "Data", "ChatLog.json")

try: 
    with open(chatlog_path, "r") as f:
        messages = load(f)
except FileNotFoundError:
    with open(chatlog_path, "w") as f:
        dump([], f)
        
def RealTimeInformation():
    current_date_time = datetime.datetime.now()
    day = current_date_time.strftime("%A")
    date = current_date_time.strftime("%d")
    month = current_date_time.strftime("%B")
    year = current_date_time.strftime("%Y")
    hour = current_date_time.strftime("%H")
    minute = current_date_time.strftime("%M")
    second = current_date_time.strftime("%S")
    
    data = f"Please use this real-time information if needed,\n"
    data += f"Day: {day}\nDate: {date}\nMonth: {month}\nYear: {year}\n"
    data += f"Time: {hour} hours: {minute} minutes: {second} seconds.\n"
    return data

def AnswerModifier(Answer):
    lines = Answer.split('\n')
    non_empty_lines = [line for line in lines if line.strip()]
    modified_answer = '\n' .join(non_empty_lines)
    return modified_answer

def analyze_query_context(query, chat_history):
    """Analyze query context to better understand incomplete or unclear speech"""
    if not query or len(query.strip()) < 3:
        return "I didn't catch that. Could you please repeat or speak a bit louder?"
    
    query_lower = query.lower().strip()
    
    # Check for very short or incomplete queries
    if len(query_lower.split()) <= 2:
        # Look at recent chat history for context
        recent_context = ""
        if chat_history and len(chat_history) > 0:
            # Get last few exchanges for context
            recent_exchanges = chat_history[-4:] if len(chat_history) > 4 else chat_history
            for exchange in recent_exchanges:
                if exchange.get("role") == "user":
                    recent_context += f"User said: {exchange.get('content', '')} "
                elif exchange.get("role") == "assistant":
                    recent_context += f"Assistant replied: {exchange.get('content', '')} "
        
        # Common incomplete patterns and their likely meanings
        if query_lower in ["what", "how", "where", "when", "why", "who"]:
            return f"Could you be more specific about what you'd like to know? For example, '{query_lower} about what?'"
        elif query_lower in ["open", "close", "play", "search", "find", "show"]:
            return f"What would you like me to {query_lower}? Please be more specific."
        elif query_lower in ["hello", "hi", "hey"]:
            return f"Hello! How can I help you today?"
        elif query_lower in ["time", "date", "weather"]:
            return f"Would you like to know the {query_lower}? I can help with that."
        elif "help" in query_lower:
            return "I'm here to help! What do you need assistance with?"
        else:
            return f"I heard '{query}' but it seems incomplete. Could you please provide more details? {recent_context}"
    
    # Check for unclear or garbled speech patterns
    unclear_patterns = [
        "um", "uh", "er", "ah", "like", "you know", "so", "well", "actually"
    ]
    
    unclear_count = sum(1 for pattern in unclear_patterns if pattern in query_lower)
    if unclear_count > 2:
        return f"I understand you're trying to communicate something. Could you please rephrase that more clearly?"
    
    return query  # Return original query if it seems complete enough

def ChatBot(Query):
    """This function sends the user's query to the chatbot and returns AI's response."""
    try:
        # Load chat history for context analysis
        with open(chatlog_path, "r") as f:
            messages = load(f)
        
        # Analyze query context for better understanding of incomplete speech
        analyzed_query = analyze_query_context(Query, messages)
        
        # If the context analysis suggests the query is too unclear, return early
        if analyzed_query != Query and "I didn't catch that" in analyzed_query:
            return analyzed_query
        
        # Check if query involves web scraping with a strict time budget
        web_scraping_response = ""
        scraping_deadline_seconds = 3.0  # hard cap for realtime
        start_scrape_time = time.perf_counter()
        try:
            from Backend.UltraFastWebScrapingIntegration import integrate_web_scraping_ultra_fast
            web_scraping_response = integrate_web_scraping_ultra_fast(analyzed_query)
        except ImportError:
            try:
                from Backend.FastWebScrapingIntegration import integrate_web_scraping_fast
                web_scraping_response = integrate_web_scraping_fast(analyzed_query)
            except ImportError:
                web_scraping_response = integrate_web_scraping(analyzed_query)

        # If scraping exceeded budget or returned a very long string, trim/skip for speed
        if time.perf_counter() - start_scrape_time > scraping_deadline_seconds:
            web_scraping_response = ""
        elif web_scraping_response and len(web_scraping_response) > 1200:
            web_scraping_response = web_scraping_response[:1200] + "..."

        if web_scraping_response:
            # If web scraping was performed, include the result in the context
            enhanced_query = f"{analyzed_query}\n\nWeb scraping result: {web_scraping_response}"
        else:
            enhanced_query = analyzed_query

        messages.append({"role": "user", "content": f"{enhanced_query}"})

        # Keep only recent context to speed up responses (last 6 exchanges max)
        if len(messages) > 12:
            messages = messages[-12:]

        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",  # Upgraded for better responses
            messages=SystemChatBot + [{"role": "system", "content": RealTimeInformation()}] + messages,
            max_tokens=2048,  # Let AI decide response length
            temperature=0.7,  # More creative
            top_p=0.9,
            stream=True,
            stop=None,
        )

        # Stream without artificial limits - let AI complete naturally
        Answer = ""
        for chunk in completion:
            if chunk.choices[0].delta.content:
                Answer += chunk.choices[0].delta.content

        Answer = Answer.replace("</s>", "")
        messages.append({"role": "assistant", "content": Answer})

        with open(chatlog_path, "w") as f:
            dump(messages, f, indent=4)

        return AnswerModifier(Answer=Answer)

    except Exception as e:
        print(f"Error: {e}")
        with open(chatlog_path, "w") as f:
            dump([], f, indent=4)
        return ChatBot(Query)
    
if __name__ == "__main__":
    while True:
        user_input = input("Enter Your Question: ")
        print(ChatBot(user_input))